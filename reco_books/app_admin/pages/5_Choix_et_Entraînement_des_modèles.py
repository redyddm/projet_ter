import streamlit as st
import pandas as pd
import pickle
from pathlib import Path
from surprise import SVD, Dataset, Reader
from recommandation_de_livres.config import MODELS_DIR, PROCESSED_DATA_DIR
from recommandation_de_livres.loaders.load_data import load_parquet

st.title("âš™ï¸ EntraÃ®nement du modÃ¨le SVD")

# --- Choix du dataset ---
DIR = st.session_state.get("DIR", None)

if not DIR:
    st.error("âš ï¸ Aucun dataset sÃ©lectionnÃ©. Retournez Ã  l'accueil.")
    st.stop()

features_path = PROCESSED_DATA_DIR / DIR / "collaborative_dataset.parquet"
if not features_path.exists():
    st.error(f"Fichier introuvable : {features_path}")
    st.stop()

st.title(f"ğŸ§  GÃ©nÃ©ration des Features - {DIR}")

model_path = MODELS_DIR / DIR / "collaborative_model.pkl"

# --- HyperparamÃ¨tres ---
st.subheader("ğŸ”§ HyperparamÃ¨tres du modÃ¨le")
n_factors = st.number_input("Nombre de facteurs latents", min_value=10, max_value=500, value=50, step=10)
n_epochs = st.number_input("Nombre d'epochs", min_value=5, max_value=200, value=50, step=5)
lr_all = st.number_input("Learning rate", min_value=0.0001, max_value=0.1, value=0.002, step=0.001, format="%.4f")
reg_all = st.number_input("RÃ©gularisation", min_value=0.001, max_value=0.1, value=0.02, step=0.001, format="%.4f")

# --- Choix du rating scale ---
st.subheader("ğŸ“ Ã‰chelle des notes")
min_rating = st.number_input("Note minimale", min_value=1.0, max_value=10.0, value=1.0, step=0.5)
max_rating = st.number_input("Note maximale", min_value=1.0, max_value=10.0, value=5.0, step=0.5)

if min_rating >= max_rating:
    st.error("âš ï¸ La note minimale doit Ãªtre infÃ©rieure Ã  la note maximale.")
    st.stop()

rating_scale = (min_rating, max_rating)

# --- Chargement des donnÃ©es ---
st.info("Chargement des donnÃ©es...")
collaborative_df = load_parquet(features_path)
st.write(f"ğŸ“Š {len(collaborative_df)} notes chargÃ©es.")

# --- Bouton entraÃ®nement ---
if st.button("ğŸš€ Lancer l'entraÃ®nement"):
    reader = Reader(rating_scale=rating_scale)
    data = Dataset.load_from_df(collaborative_df[['user_id', 'item_id', 'rating']], reader)
    trainset = data.build_full_trainset()

    svd = SVD(
        n_factors=n_factors,
        n_epochs=n_epochs,
        lr_all=lr_all,
        reg_all=reg_all
    )

    with st.spinner("EntraÃ®nement en cours... â³"):
        svd.fit(trainset)

    # Sauvegarde du modÃ¨le
    model_path.parent.mkdir(parents=True, exist_ok=True)
    with open(model_path, 'wb') as f:
        pickle.dump(svd, f)

    st.success(f"âœ… ModÃ¨le entraÃ®nÃ© et sauvegardÃ© dans {model_path}")